{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d333a8cf-97e2-450e-80de-62d09f08327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import load\n",
    "from scipy.signal import periodogram\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91e5bc3-db5d-4c78-b92b-bf8713c6491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install pytorch -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e7a401-c208-4635-b5aa-1c5c8eb1d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加載 npz 文件\n",
    "npz_file = \"data/PEMS08.npz\"\n",
    "data = np.load(npz_file)\n",
    "distance_df = pd.read_csv(\"data/distance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b534b4-ace6-4b32-9442-cdca8c4fdf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17856, 170, 3)\n",
      "   from   to   cost\n",
      "0     9  153  310.6\n",
      "1   153   62  330.9\n",
      "2    62  111  332.9\n",
      "3   111   11  324.2\n",
      "4    11   28  336.0\n"
     ]
    }
   ],
   "source": [
    "print(data['data'].shape) # 時間段數, 車站數量或感測器數量, 特徵數量\n",
    "print(distance_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d1c8cb0-7a9f-400b-8a2f-8826d99dde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 流量, 佔有率, 速度\n",
    "# data[key][1, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4941bc40-0469-4aaf-b6f3-c63d0399b14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e0a0ecd-ba86-4594-9c37-1ecc636f2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 170\n",
    "\n",
    "# 構建鄰接矩陣\n",
    "def build_adjacency_matrix(distance_df, num_nodes):\n",
    "    adj_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    for _, row in distance_df.iterrows():\n",
    "        from_node = int(row['from'])\n",
    "        to_node = int(row['to'])\n",
    "        cost = row['cost']\n",
    "        adj_matrix[from_node, to_node] = cost\n",
    "        adj_matrix[to_node, from_node] = cost  # 無向圖\n",
    "    # return torch.tensor(adj_matrix, dtype=torch.float32)\n",
    "    return adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fe3e8f3-b1bd-4659-8c38-d83788947715",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adjacency = build_adjacency_matrix(distance_df, num_nodes)\n",
    "np.save('data/Adjacency.npy', Adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "addddf0a-9c7b-4d1e-afde-03b0288ecc92",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17856, 170, 3)\n",
      "[[[1.330e+02 6.030e-02 6.580e+01]\n",
      "  [2.100e+02 5.890e-02 6.960e+01]\n",
      "  [1.240e+02 3.580e-02 6.580e+01]\n",
      "  ...\n",
      "  [7.400e+01 2.131e-01 6.530e+01]\n",
      "  [9.400e+01 2.260e-02 6.800e+01]\n",
      "  [6.000e+00 3.100e-03 6.500e+01]]\n",
      "\n",
      " [[1.140e+02 5.320e-02 6.690e+01]\n",
      "  [1.850e+02 5.500e-02 6.850e+01]\n",
      "  [1.190e+02 3.390e-02 6.500e+01]\n",
      "  ...\n",
      "  [7.300e+01 1.469e-01 3.720e+01]\n",
      "  [8.400e+01 1.890e-02 6.870e+01]\n",
      "  [4.000e+00 1.800e-03 6.500e+01]]\n",
      "\n",
      " [[1.400e+02 6.220e-02 6.680e+01]\n",
      "  [1.710e+02 4.660e-02 6.990e+01]\n",
      "  [1.070e+02 3.360e-02 6.380e+01]\n",
      "  ...\n",
      "  [7.000e+01 5.860e-02 3.400e+01]\n",
      "  [8.200e+01 2.200e-02 6.700e+01]\n",
      "  [4.000e+00 2.100e-03 6.490e+01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.200e+02 5.810e-02 6.330e+01]\n",
      "  [1.760e+02 5.290e-02 6.680e+01]\n",
      "  [1.190e+02 5.180e-02 5.610e+01]\n",
      "  ...\n",
      "  [4.700e+01 1.551e-01 3.220e+01]\n",
      "  [9.100e+01 2.290e-02 6.640e+01]\n",
      "  [3.000e+00 1.400e-03 6.530e+01]]\n",
      "\n",
      " [[1.020e+02 5.790e-02 6.140e+01]\n",
      "  [1.650e+02 4.920e-02 6.720e+01]\n",
      "  [1.330e+02 5.070e-02 5.890e+01]\n",
      "  ...\n",
      "  [9.700e+01 1.265e-01 3.080e+01]\n",
      "  [8.500e+01 2.080e-02 6.750e+01]\n",
      "  [2.000e+00 1.000e-03 6.520e+01]]\n",
      "\n",
      " [[1.020e+02 5.650e-02 6.170e+01]\n",
      "  [1.660e+02 5.020e-02 6.760e+01]\n",
      "  [1.330e+02 4.640e-02 5.630e+01]\n",
      "  ...\n",
      "  [8.300e+01 2.730e-02 5.910e+01]\n",
      "  [7.000e+01 1.880e-02 6.660e+01]\n",
      "  [6.000e+00 2.600e-03 6.520e+01]]]\n"
     ]
    }
   ],
   "source": [
    "lst = data.files\n",
    "print(data[lst[0]].shape)\n",
    "print(data[lst[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceceb17-eb70-4cdf-a161-746f3265fa89",
   "metadata": {},
   "source": [
    "The file gives a numpy array with dimensions (17856, 170, 3), which are in the form of (timesteps, location, features). For the 3 features, the order is flow,occupy,speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0467e246-1952-4835-91d1-0e2dbd2d4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_data = data[lst[0]]\n",
    "data_dict = []\n",
    "# loop for every timestep and every location and add as a single row\n",
    "for timestep in range(traffic_data.shape[0]):\n",
    "    for location in range(traffic_data.shape[1]):\n",
    "        data_dict.append({\n",
    "            \"timestep\" : timestep+1,\n",
    "            \"location\" : location,\n",
    "            \"flow\"     : traffic_data[timestep][location][0],\n",
    "            \"occupy\"   : traffic_data[timestep][location][1],\n",
    "            \"speed\"    : traffic_data[timestep][location][2]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53267525-ffdc-43b8-969a-2f57c9692f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data_dict)\n",
    "# df.to_csv(\"data/traffic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad5d20fa-7050-4abc-9ee7-c7745bb62d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestep</th>\n",
       "      <th>location</th>\n",
       "      <th>flow</th>\n",
       "      <th>occupy</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.0603</td>\n",
       "      <td>65.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>69.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>65.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>69.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035515</th>\n",
       "      <td>17856</td>\n",
       "      <td>165</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>68.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035516</th>\n",
       "      <td>17856</td>\n",
       "      <td>166</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035517</th>\n",
       "      <td>17856</td>\n",
       "      <td>167</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>59.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035518</th>\n",
       "      <td>17856</td>\n",
       "      <td>168</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>66.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035519</th>\n",
       "      <td>17856</td>\n",
       "      <td>169</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>65.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3035520 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestep  location   flow  occupy  speed\n",
       "0               1         0  133.0  0.0603   65.8\n",
       "1               1         1  210.0  0.0589   69.6\n",
       "2               1         2  124.0  0.0358   65.8\n",
       "3               1         3  145.0  0.0416   69.6\n",
       "4               1         4  206.0  0.0493   69.4\n",
       "...           ...       ...    ...     ...    ...\n",
       "3035515     17856       165   74.0  0.0233   68.9\n",
       "3035516     17856       166   11.0  0.0082   64.0\n",
       "3035517     17856       167   83.0  0.0273   59.1\n",
       "3035518     17856       168   70.0  0.0188   66.6\n",
       "3035519     17856       169    6.0  0.0026   65.2\n",
       "\n",
       "[3035520 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic = pd.read_csv(\"data/traffic.csv\")\n",
    "traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c371e24-3d23-4063-8eb7-0d4af8aa1044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000, 371.6000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000, 371.6000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        ...,\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000, 172.4000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ..., 172.4000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82a16b29-e8eb-4ffe-bb37-075f9beadaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating 3-dimensional array for [timestep, timeframe, features]\n",
    "def create_dataset(location, WINDOW_SIZE):\n",
    "    \n",
    "    # mask a certain location\n",
    "    location_current = traffic[traffic[\"location\"]==location].reset_index()\n",
    "    \n",
    "    # group to hour and average 12 (5-minute) timesteps\n",
    "    location_current[\"hour\"] = ((location_current[\"timestep\"] - 1) // 12)\n",
    "    grouped = location_current.groupby(\"hour\").mean().reset_index()\n",
    "    \n",
    "    # add hour features as mod 24 cycle (0...23)\n",
    "    grouped['day'] = (grouped['hour'] // 24) % 7\n",
    "    grouped['hour'] %= 24\n",
    "    \n",
    "    one_hot_hour = pd.get_dummies(grouped['hour'])\n",
    "    one_hot_hour = one_hot_hour.add_prefix('hour_')\n",
    "    \n",
    "    # merge all the features together to get a total of 27 features\n",
    "    hour_grouped = pd.concat([grouped[[\"occupy\", \"flow\", \"speed\"]], one_hot_hour], axis=1)\n",
    "    hour_grouped = np.array(hour_grouped)\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    # add lag features (in reverse time order)\n",
    "    for i in range(len(hour_grouped) - WINDOW_SIZE):\n",
    "        X.append(hour_grouped[i:(i + WINDOW_SIZE)][::-1]) # reverse the order\n",
    "        Y.append(hour_grouped[i + WINDOW_SIZE, 0]) # index 0 is occupy\n",
    "    \n",
    "    return X,Y # returns (timestep, timeframe, features) and (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c2bc7e3-1f81-4397-a3d9-93b63899b182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1464, 24, 27, 170)\n",
      "(1464, 170)\n"
     ]
    }
   ],
   "source": [
    "# creating 4-th dimension for the locations\n",
    "X, Y = [], []\n",
    "\n",
    "for location in range(170):\n",
    "    a,b = create_dataset(location, WINDOW_SIZE=24)\n",
    "    X.append(a)\n",
    "    Y.append(b)\n",
    "    \n",
    "X = np.moveaxis(X,0,-1)\n",
    "Y = np.moveaxis(Y,0,-1)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a59cd66-811d-4d97-8195-1b8ba509bf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1171, 24, 27, 170)\n",
      "(1171, 170)\n",
      "(293, 24, 27, 170)\n",
      "(293, 170)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 0.8\n",
    "TEST_SIZE  = 0.2\n",
    "\n",
    "train_size = int(len(X) * TRAIN_SIZE)\n",
    "test_size  = int(len(X) * TEST_SIZE)\n",
    "\n",
    "train_X, train_Y = X[:train_size], Y[:train_size]\n",
    "test_X, test_Y = X[train_size:], Y[train_size:]\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfd4a53d-7b04-4a1d-ac21-d01218ca57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "scaler_Y = MinMaxScaler()\n",
    "train_X = scaler_X.fit_transform(train_X.reshape(train_X.shape[0] * train_X.shape[1], -1)) \\\n",
    "                   .reshape(train_X.shape[0], train_X.shape[1], -1)\n",
    "test_X = scaler_X.transform(test_X.reshape(test_X.shape[0] * test_X.shape[1], -1)) \\\n",
    "                   .reshape(test_X.shape[0], test_X.shape[1], -1)\n",
    "train_Y = scaler_Y.fit_transform(train_Y)\n",
    "test_Y = scaler_Y.transform(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e1e84e4-b601-4dff-95d5-3bfdf1d224dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(256, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])),\n",
    "    LSTM(256, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(170, activation='linear'),\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71240659-0e9d-4ca0-b65a-1dc162150928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils.vis_utils import plot_model\n",
    "# plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58a6c46f-2f10-4cf7-a5e2-ff25e8b0ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# history = model.fit(train_X, train_Y, epochs=150, batch_size=32, validation_split=0.1, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
