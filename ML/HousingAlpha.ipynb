{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f25c2d-d665-445b-8937-ee317aff8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import gudhi.representations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gudhi as gd \n",
    "import subprocess as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from persim.persistent_entropy import *\n",
    "\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b703bbc-9222-4eee-a543-22154d5df9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_all = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "y_all = housing['target']\n",
    "\n",
    "X_all = X_all.iloc[:3000]\n",
    "y_all = y_all[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e6348a-37db-41e1-875b-9b87ee5c2dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.642119</td>\n",
       "      <td>0.828791</td>\n",
       "      <td>0.281990</td>\n",
       "      <td>-0.123927</td>\n",
       "      <td>-0.997996</td>\n",
       "      <td>-0.331205</td>\n",
       "      <td>0.202650</td>\n",
       "      <td>-0.604776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.629035</td>\n",
       "      <td>-0.649917</td>\n",
       "      <td>0.111970</td>\n",
       "      <td>-0.179877</td>\n",
       "      <td>1.296598</td>\n",
       "      <td>-0.881856</td>\n",
       "      <td>0.189239</td>\n",
       "      <td>-0.598947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.055091</td>\n",
       "      <td>1.642080</td>\n",
       "      <td>0.579190</td>\n",
       "      <td>-0.070446</td>\n",
       "      <td>-0.805952</td>\n",
       "      <td>-0.026418</td>\n",
       "      <td>0.182533</td>\n",
       "      <td>-0.610606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.167623</td>\n",
       "      <td>1.642080</td>\n",
       "      <td>0.016067</td>\n",
       "      <td>-0.070863</td>\n",
       "      <td>-0.737523</td>\n",
       "      <td>-0.340607</td>\n",
       "      <td>0.182533</td>\n",
       "      <td>-0.616435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.179770</td>\n",
       "      <td>1.642080</td>\n",
       "      <td>0.121933</td>\n",
       "      <td>-0.062220</td>\n",
       "      <td>-0.729797</td>\n",
       "      <td>-0.793367</td>\n",
       "      <td>0.182533</td>\n",
       "      <td>-0.616435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  2.642119  0.828791  0.281990  -0.123927   -0.997996 -0.331205  0.202650   \n",
       "1  2.629035 -0.649917  0.111970  -0.179877    1.296598 -0.881856  0.189239   \n",
       "2  2.055091  1.642080  0.579190  -0.070446   -0.805952 -0.026418  0.182533   \n",
       "3  1.167623  1.642080  0.016067  -0.070863   -0.737523 -0.340607  0.182533   \n",
       "4  0.179770  1.642080  0.121933  -0.062220   -0.729797 -0.793367  0.182533   \n",
       "\n",
       "   Longitude  \n",
       "0  -0.604776  \n",
       "1  -0.598947  \n",
       "2  -0.610606  \n",
       "3  -0.616435  \n",
       "4  -0.616435  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_all)\n",
    "X_scaled = pd.DataFrame(scaler.transform(X_all), index= X_all.index, columns= X_all.columns)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a44a35a-5dd8-4f37-ae40-888984c10d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5199604295289464\n",
      "R-square: 0.7010017152481347\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_all, test_size=0.5, random_state=43)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "predictions_lr = lr.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions_lr))\n",
    "r2 = r2_score(y_test, predictions_lr)\n",
    "\n",
    "print('RMSE:', rmse)\n",
    "print('R-square:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eeb594-c56c-4366-9654-1fb7941eba27",
   "metadata": {},
   "source": [
    "## Add Topo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "595e2b46-c626-43ea-b9b1-2a43194eabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7004076-819b-4fed-b276-099a0bbe0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_infinity = lambda alpha_list: [alpha for alpha in alpha_list if alpha[1] != np.inf]\n",
    "\n",
    "def compute_persistence(data_remove):\n",
    "    print(f\"進程 {os.getpid()} 開始計算\")\n",
    "    \n",
    "    # PCA\n",
    "    pca_result = pca.fit_transform(data_remove)\n",
    "    # Alpha complex\n",
    "    alpha_complex = gd.AlphaComplex(points = pca_result)\n",
    "    st_alpha = alpha_complex.create_simplex_tree()\n",
    "    alpha_filtration = st_alpha.get_filtration()\n",
    "    alpha_list = list(alpha_filtration)\n",
    "    # Filter\n",
    "    filtered_alpha_list = remove_infinity(alpha_list)\n",
    "    dgm = np.array([[0.0, value] for _, value in filtered_alpha_list])\n",
    "    dgm_filtered = np.array([bar for bar in dgm if bar[1] - bar[0] != 0])\n",
    "    ## entropy\n",
    "    PE = gd.representations.Entropy()\n",
    "    pe_normal = PE.fit_transform([dgm_filtered])\n",
    "    \n",
    "    print(f\"進程 {os.getpid()} 完成計算\")\n",
    "    return pe_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8a28f4e-9d77-4f1f-9202-294aa062866d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 100 out of 3000\n",
      "Processing row 200 out of 3000\n",
      "Processing row 300 out of 3000\n",
      "Processing row 400 out of 3000\n",
      "Processing row 500 out of 3000\n",
      "Processing row 600 out of 3000\n",
      "Processing row 700 out of 3000\n",
      "Processing row 800 out of 3000\n",
      "Processing row 900 out of 3000\n",
      "Processing row 1000 out of 3000\n",
      "Processing row 1100 out of 3000\n",
      "Processing row 1200 out of 3000\n",
      "Processing row 1300 out of 3000\n",
      "Processing row 1400 out of 3000\n",
      "Processing row 1500 out of 3000\n",
      "Processing row 1600 out of 3000\n",
      "Processing row 1700 out of 3000\n",
      "Processing row 1800 out of 3000\n",
      "Processing row 1900 out of 3000\n",
      "Processing row 2000 out of 3000\n",
      "Processing row 2100 out of 3000\n",
      "Processing row 2200 out of 3000\n",
      "Processing row 2300 out of 3000\n",
      "Processing row 2400 out of 3000\n",
      "Processing row 2500 out of 3000\n",
      "Processing row 2600 out of 3000\n",
      "Processing row 2700 out of 3000\n",
      "Processing row 2800 out of 3000\n",
      "Processing row 2900 out of 3000\n",
      "Processing row 3000 out of 3000\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for i in range(X_scaled.shape[0]):\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Processing row {i + 1} out of {X_scaled.shape[0]}\")\n",
    "        gc.collect()\n",
    "        \n",
    "    data_remove = X_scaled.drop(index=i)\n",
    "    data_list.append(data_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae280f45-dcb9-46aa-88c9-d4eecb5969b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平行運算時間:  63.30636692047119\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# 使用 joblib 進行平行運算\n",
    "results = Parallel(n_jobs=-1)(delayed(compute_persistence)(data) for data in data_list)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"平行運算時間: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59ba806e-3ad9-40f0-b1b0-3d1c1138c8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.19216821]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6c4ae42-8b55-4a72-8046-a222d2be23f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w2/_g9w5yys0f171q4qqm469z1h0000gn/T/ipykernel_59758/3442341204.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mst_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_complex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simplex_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0malpha_filtration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst_alpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filtration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0malpha_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_filtration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Remove Infinity\n",
    "remove_infinity = lambda alpha_list: [alpha for alpha in alpha_list if alpha[1] != np.inf]\n",
    "\n",
    "entropy_feature = []\n",
    "\n",
    "start = time.time()\n",
    "for i in range(X_scaled.shape[0]):\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Processing row {i + 1} out of {X_scaled.shape[0]}\")\n",
    "        gc.collect()\n",
    "        \n",
    "    data_remove = X_scaled.drop(index=i)\n",
    "    \n",
    "    # PCA\n",
    "    pca_result = pca.fit_transform(data_remove)\n",
    "    \n",
    "    # Alpha complex\n",
    "    alpha_complex = gd.AlphaComplex(points = pca_result)\n",
    "    st_alpha = alpha_complex.create_simplex_tree()\n",
    "    alpha_filtration = st_alpha.get_filtration()\n",
    "    alpha_list = list(alpha_filtration)\n",
    "    \n",
    "    # Filter\n",
    "    filtered_alpha_list = remove_infinity(alpha_list)\n",
    "    dgm = np.array([[0.0, value] for _, value in filtered_alpha_list])\n",
    "    dgm_filtered = np.array([bar for bar in dgm if bar[1] - bar[0] != 0])\n",
    "    \n",
    "    ## entropy\n",
    "    PE = gd.representations.Entropy()\n",
    "    pe_normal = PE.fit_transform([dgm_filtered])\n",
    "    \n",
    "    entropy_feature.append(pe_normal)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"ripser++ total time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d9af72a-0362-49d2-aada-9585a2551e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.69681062]]),\n",
       " array([[0.9978935]]),\n",
       " array([[0.69627529]]),\n",
       " array([[0.71394814]]),\n",
       " array([[0.69763886]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_feature[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57fba276-a299-42dc-abb6-27e9d2922117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.69681062]]),\n",
       " array([[0.9978935]]),\n",
       " array([[0.69627529]]),\n",
       " array([[0.71394814]]),\n",
       " array([[0.69763886]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0deb34ea-d8f0-401b-9e98-d184142e3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_scaled['topo_feature'] = [x.tolist()[0][0] if isinstance(x, np.ndarray) else x for x in entropy_feature]\n",
    "# X_scaled['topo_feature'] = scaler.fit_transform(X_scaled[['topo_feature']])\n",
    "# X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b5fd5bd-f9b3-4d03-a5d3-e9335c53bde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5545262813691066\n",
      "R-square: 0.6644448697913721\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_all, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = pd.Series(y_train).reset_index(drop=True)\n",
    "y_test = pd.Series(y_test).reset_index(drop=True)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "predictions_lr = lr.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions_lr))\n",
    "r2 = r2_score(y_test, predictions_lr)\n",
    "\n",
    "print('RMSE:', rmse)\n",
    "print('R-square:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a747c-6ca7-43f7-ad3d-29417dfe91b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
