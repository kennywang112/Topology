{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f25c2d-d665-445b-8937-ee317aff8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import ssl\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gudhi as gd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from persim.persistent_entropy import *\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b703bbc-9222-4eee-a543-22154d5df9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_all = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "y_all = housing['target']\n",
    "\n",
    "X_all = X_all#.iloc[:3000]\n",
    "y_all = y_all#[:3000]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_all)\n",
    "X_scaled = pd.DataFrame(scaler.transform(X_all), index=X_all.index, columns=X_all.columns)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a44a35a-5dd8-4f37-ae40-888984c10d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7195934214967924\n",
      "R-square: 0.6113250004234638\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_all, test_size=0.5, random_state=43)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "predictions_lr = lr.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions_lr))\n",
    "r2 = r2_score(y_test, predictions_lr)\n",
    "\n",
    "print('RMSE:', rmse)\n",
    "print('R-square:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eeb594-c56c-4366-9654-1fb7941eba27",
   "metadata": {},
   "source": [
    "### Add Topology feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7004076-819b-4fed-b276-099a0bbe0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_infinity = lambda alpha_list: [alpha for alpha in alpha_list if alpha[1] != np.inf]\n",
    "\n",
    "def compute_persistence(data_remove):\n",
    "    print(f\"進程 {os.getpid()} 開始計算\")\n",
    "    \n",
    "    # PCA\n",
    "    pca_result = pca.fit_transform(data_remove)\n",
    "    # Alpha complex\n",
    "    alpha_complex = gd.AlphaComplex(points = pca_result)\n",
    "    st_alpha = alpha_complex.create_simplex_tree()\n",
    "    alpha_filtration = st_alpha.get_filtration()\n",
    "    alpha_list = list(alpha_filtration)\n",
    "    # Filter\n",
    "    filtered_alpha_list = remove_infinity(alpha_list)\n",
    "    dgm = np.array([[0.0, value] for _, value in filtered_alpha_list])\n",
    "    dgm_filtered = np.array([bar for bar in dgm if bar[1] - bar[0] != 0])\n",
    "    ## entropy\n",
    "    PE = gd.representations.Entropy()\n",
    "    pe_normal = PE.fit_transform([dgm_filtered])\n",
    "    \n",
    "    print(f\"進程 {os.getpid()} 完成計算\")\n",
    "    return pe_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc6bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = Data_list(X_scaled)\n",
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae280f45-dcb9-46aa-88c9-d4eecb5969b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平行運算時間:  63.30636692047119\n"
     ]
    }
   ],
   "source": [
    "results = Parrallel_compute(data_list, typeComplex='AlphafromCechmate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58303596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Infinity\n",
    "remove_infinity = lambda alpha_list: [alpha for alpha in alpha_list if alpha[1] != np.inf]\n",
    "\n",
    "entropy_feature = []\n",
    "\n",
    "start = time.time()\n",
    "for i in range(X_scaled.shape[0]):\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Processing row {i + 1} out of {X_scaled.shape[0]}\")\n",
    "        gc.collect()\n",
    "        \n",
    "    data_remove = X_scaled.drop(index=i)\n",
    "    \n",
    "    # PCA\n",
    "    pca_result = pca.fit_transform(data_remove)\n",
    "    \n",
    "    # Alpha complex\n",
    "    alpha_complex = gd.AlphaComplex(points = pca_result)\n",
    "    st_alpha = alpha_complex.create_simplex_tree()\n",
    "    alpha_filtration = st_alpha.get_filtration()\n",
    "    alpha_list = list(alpha_filtration)\n",
    "    \n",
    "    # Filter\n",
    "    filtered_alpha_list = remove_infinity(alpha_list)\n",
    "    dgm = np.array([[0.0, value] for _, value in filtered_alpha_list])\n",
    "    dgm_filtered = np.array([bar for bar in dgm if bar[1] - bar[0] != 0])\n",
    "    \n",
    "    ## entropy\n",
    "    PE = gd.representations.Entropy()\n",
    "    pe_normal = PE.fit_transform([dgm_filtered])\n",
    "    \n",
    "    entropy_feature.append(pe_normal)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"ripser++ total time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b5fd5bd-f9b3-4d03-a5d3-e9335c53bde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5545262813691066\n",
      "R-square: 0.6644448697913721\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_all, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = pd.Series(y_train).reset_index(drop=True)\n",
    "y_test = pd.Series(y_test).reset_index(drop=True)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "predictions_lr = lr.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions_lr))\n",
    "r2 = r2_score(y_test, predictions_lr)\n",
    "\n",
    "print('RMSE:', rmse)\n",
    "print('R-square:', r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
